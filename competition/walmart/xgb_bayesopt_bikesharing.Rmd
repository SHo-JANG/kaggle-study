---
title: "Untitled"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```

# Preparations (준비작업) {.tabset .tabset-fade}

## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(lubridate)
library(skimr)
library(magrittr)
library(data.table)
library(gridExtra)
library(themis)


theme_set(theme_bw())
```

## Data load

```{r}
file_path <- "C:/Users/sangdon/Desktop/kaggle-study/input/bike-sharing-demand/"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv"))
test <- read_csv(file.path(file_path, "test.csv"))
```

# Data overview (데이터 기본정보) {.tabset .tabset-fade}

## train data

```{r}
head(train)
skim(train)
```

## test data

```{r}
head(test)
skim(test)

test %>% 
  summarise(across(.fns = ~sum(is.na(.))/length(.)))

```

# 데이터 전처리 {.tabset .tabset-fade}

## train, test 데이터 통합

```{r}
all_data <- bind_rows(train, test)

```

## 변수 속성 변경

```{r}
all_data$season <- factor(all_data$season, labels = c('winter', 'fall', 'summer', 'spring'))
all_data$weather <- as.factor(all_data$weather)
all_data$workingday <- as.factor(all_data$workingday)
all_data$holiday <- as.factor(all_data$holiday)
```

## 날짜 변수 생성

```{r}
all_data %>% mutate(year = year(datetime), 
                    month = month(datetime),
                    wday = wday(datetime),
                    day = day(datetime), 
                    hour = hour(datetime)) %>% 
    select(year, month, wday, day, holiday, workingday, everything()) -> all_data
```

## wday, month factor로 변환

```{r}
all_data$wday <- factor(all_data$wday, labels = c('Sun', 'Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat'))
all_data$month <- as.factor(all_data$month)
```

# 일변량 데이터 시각화 {.tabset .tabset-fade}

## count(target variable) 분포

```{r, message=FALSE, warning=FALSE}
all_data %>% 
    ggplot(aes(x = count)) + 
    geom_histogram()
```

count 변수를 보면 0인 count가 많음

## atemp, temp 분포

```{r, warning=FALSE, message=FALSE}
p1 <- all_data %>% 
    ggplot(aes(x = atemp)) + 
    geom_histogram()
p2 <- all_data %>% 
    ggplot(aes(x = temp)) + 
    geom_histogram()

grid.arrange(grobs = list(p1, p2), col = 2)
```

temp, atemp 분포는 거의 비슷함

## casual, registered 분포

```{r}
all_data %>% 
  ggplot(aes(x = registered)) + 
  geom_histogram()

all_data %>% 
  ggplot(aes(x = casual)) + 
  geom_histogram()


var(all_data$registered, na.rm = T)
mean(all_data$registered, na.rm = T)

var(all_data$casual, na.rm = T)
mean(all_data$casual, na.rm = T)

```

train data에는 존재하지만 test 데이터에는 존재하지 않는 count variable이다. 두 변수의 분포를 보면 0의 비율이 매우 많고, 과대산포되어있는 것을 볼 수 있다.

## 변수별 상관관계 및 분포 시각화(holiday)

```{r}
all_data %>% 
    select(holiday, temp, humidity, windspeed, count) %>% 
    GGally::ggpairs(mapping = aes(color = holiday))
```

## 변수별 상관관계 및 분포 시각화(workingday)

```{r}
all_data %>% 
    select(workingday, temp, humidity, windspeed, count) %>% 
    GGally::ggpairs(mapping = aes(color = workingday))
```

# factor 변수 시각화 {.tabset .tabset-fade}

## 계절(season)에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(season, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = season)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 날씨(weather)에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(weather, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = weather)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 요일(wday)에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(wday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = wday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## 휴일 유무(holiday)에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(holiday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = holiday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## workingday에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(workingday, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = workingday)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## month에 따른 시간 vs count 그래프

```{r}
all_data %>% 
    group_by(month, hour) %>% 
    summarise(count = sum(count, na.rm = T)) %>% 
    ggplot(aes(x = hour, y = count, color = month)) +
    geom_line(size = 1.5, alpha = 0.7)
```

## hour에 따른 temp vs atemp 그래프

```{r}
a1 <- all_data %>% 
  mutate(hour = as.factor(hour)) %>% 
  ggplot(aes(x=hour, y = registered)) + geom_boxplot()

a2 <- all_data %>% 
  mutate(hour = as.factor(hour)) %>% 
  ggplot(aes(x=hour, y = casual)) + geom_boxplot()

grid.arrange(a1, a2)
```

# 결측치 및 factor level 처리

humidity의 경우 0 값이 22개 존재함. humidiy 값이 0인 경우를 결측치 대체함. windspeed가 0인 경우도 마찬가지로 결측치로 보고 대체함 weather의 경우 4 level의 빈도가 매우 작기 때문에 3 level과 통합

```{r}
table(all_data$weather)
table(all_data$humidity==0) # 22 
table(all_data$windspeed==0) # 2180
table(all_data$casual==0) # 986
table(all_data$registered==0) # 15

all_data$humidity[all_data$humidity == 0] <- NA
all_data$windspeed[all_data$windspeed == 0] <- NA


all_data %>% 
    recipe(count~.) %>% 
    step_other(weather, threshold = 0.1, other = 3) %>% 
    step_meanimpute(humidity) %>%
    step_bagimpute(windspeed, impute_with = imp_vars(season, weather, temp, atemp, month, year, humidity), trees = 100) %>% 
    prep(training = all_data) %>% 
    bake(new_data = all_data) -> all_data
```

# Recipe + preperation {.tabset .tabset-fade}

```{r}
all_data %>% names()
bike_res <- all_data %>% 
  recipe(count~.) %>% 
  step_rm(datetime, registered, casual) %>%
  step_mutate(year = as.factor(year)) %>% 
  step_log(count, offset = 1) %>%
  step_dummy(all_nominal()) %>%
  step_nzv(all_numeric()) %>% 
  prep(training = all_data)
    
```

# Juice {.tabset .tabset-fade}

```{r}
all_data2 <- juice(bike_res)
```

# train, test 나누기 {.tabset .tabset-fade}

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

# XGboost setting {.tabset .tabset-fade}

## XGBOOST hyperparameter 세팅

```{r}
xgb_spec <- boost_tree(
    trees = 1000, # 앙상블에 포함되는 tree의 수 
    tree_depth = tune(), # 얼마만큼 노드를 split할건지 
    min_n = tune(), # 노드를 분할하는데 필요한 최소 데이터의 수
    loss_reduction = tune(), # 노드 분할에 필요한 loss의 감소량 
    sample_size = tune(), # The amount of data exposed to the fitting routine
    mtry = tune(), # The number of predictors that will be randomly sampled at each split when creating the tree models. 
    learn_rate = tune() 
) %>% 
    set_engine('xgboost', objective = "reg:squarederror") %>% 
    set_mode('regression')

params <- parameters(xgb_spec) %>% 
    finalize(train2)
```

# XGboost workflow {.tabset .tabset-fade}

## workflow에 모델 세팅

```{r}
xgb_wf <- workflow() %>% 
    add_formula(count~.) %>% 
    add_model(xgb_spec)
```

## 교차검증 데이터 세팅(cross validation)

```{r}
set.seed(2021)
vb_folds <- vfold_cv(train2, v = 5, strata = count)
vb_folds
```

## hyperparameter 튜닝

```{r}
library(tictoc)
tic()
doParallel::registerDoParallel()
xgb_res <- tune_bayes(
    object = xgb_wf, # recipe, formula를 지정해준 workflow 
    resamples = vb_folds, 
    param_info = params, 
    iter = 30, 
    metrics = metric_set(rmse), 
    initial = 10, 
    control = control_bayes(
        verbose = TRUE, 
        no_improve = 10, 
        seed = 123) 
)
toc()  
```

## Final 모델 workflow에 세팅

```{r}
best_param <- select_best(xgb_res, 'rmse')
final_xgb <- finalize_workflow(xgb_wf, best_param)
final_xgb
```

## final 모델 세팅

```{r}
final_model <- finalize_model(xgb_spec, best_param) 
final_model # tuning이 끝난 최종 모형 
```

## final model workflow에 업데이트

```{r}
final_workflow <- xgb_wf %>% update_model(final_model)
```

## final model 학습

```{r}
xgb_fit <- fit(final_workflow, data = train2)
```

# 모델 학습 결과 {.tabset .tabset-fade}

## 모델 예측값 산출

```{r}
pred_xgb <- 
    predict(xgb_fit, test2) %>% 
    mutate(modelo = "XGBoost")
pred_xgb %>% head()

pred_xgb$.pred <- exp(pred_xgb$.pred)-1
```

## 변수 중요도 그림(feature importance plot)

```{r}
library(vip) # feature importance plot 그리기 
final_xgb %>% 
    fit(data = train2) %>%  # iter, training_rmse 
    pull_workflow_fit() %>% #  http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/
    vip(geom = 'point')
```

# 파일 제출 {.tabset .tabset-fade}

```{r}
subfile <- read_csv(file.path(file_path, "sampleSubmission.csv"))
subfile$count <- pred_xgb$.pred

write.csv(subfile, row.names = FALSE,
          file.path(file_path, "xgb_Submission_bayestuning.csv")) 
```

---
title: "Walmart baseline with tidymodels"
subtitle: "더미 코딩의 위력😲"
author: "Issac Lee"
date: "2/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![Photo steal from [here](https://connectedremag.com/das-in-building-wireless/walmart-verizon-explore-testing-5g-in-some-stores/)](https://connectedremag.com/wp-content/uploads/2020/03/walmart-5G-connected-real-estate.png)

본 포스팅은 [슬기로운 통계생활 캐글 R 스터디](https://www.youtube.com/playlist?list=PLKtLBdGREmMlJCXjCpCi5B4KQ-TsFvAAi) 발표용 포스팅입니다.


## 목표

Walmart 매출 예측 대회의 베이스라인 모델을 `tidymodels`를 사용하여 잡아본다.

## 준비작업 {.tabset .tabset-fade}

### Library load

이번 포스팅에서 사용할 R패키지들을 불러오자. 특히 요즘 핫하디 핫한 `tidymodels` 사용하여 월마트 대회를 가지고 놀아본다. 또한 마이 빼이보릿 연산자들을 사용하기 위하여 `magrittr`를 불러왔다.🤣

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(magrittr)
library(skimr)
library(knitr)
theme_set(theme_bw())
```

### Dataset load

이 대회에서 주어진 데이터셋을 불러보자. 주어진 파일 리스트는 다음과 같다.

```{r}
file_path <- "../input/walmart-recruiting-store-sales-forecasting/"
files <- list.files(file_path)
files
```
각 변수의 이름을 `janitor` 패키지로 말끔하게 바꿔준다.

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv.zip")) %>% 
  janitor::clean_names()
test <- read_csv(file.path(file_path, "test.csv.zip")) %>% 
  janitor::clean_names()
features <- read_csv(file.path(file_path, "features.csv.zip")) %>% 
  janitor::clean_names()
stores <- read_csv(file.path(file_path, "stores.csv")) %>% 
  janitor::clean_names()
```

## 각 데이터 셋 정보확인

각 `train`과 `test` 셋의 크기와 변수 이름을 확인하자. `test` 셋에는 우리가 예측하고자 하는 변수인 `Weekly_Sales`가 포함되어 있지 않음을 알 수 있다.

```{r}
# size of data
dim(train)
dim(test)

# train
names(train)
train %>% head()

# test
names(test)
test %>% head()
```

## 전처리를 위한 alldata 생성

전처리 과정을 거칠 때 `train`과 `test`셋을 합쳐놓으면 편한점이 많으므로, `all_data`로 합쳐놓기로 하자.

```{r}
# alldata combine
all_data <- bind_rows(train, test)
names(all_data)

all_data %>% head()
all_data %>% skim()
```

## tidymodels - recipe을 이용한 전처리

가장 간단한 전처리를 한다. 숫자 변수 (numeric)들을 normalize 시키는 `step_normalize()`를 이용해서 평균과 분산을 계산, 스케일링을 시행함.

```{r}
walmart_recipe <- 
    recipe(weekly_sales ~ .,
           data = all_data) %>% 
    step_mutate(year = lubridate::year(date),
                month = lubridate::month(date)) %>%
    step_rm(date) %>% 
    step_mutate(year = factor(year),
                month = factor(month),
                store = factor(store),
                dept = factor(dept)) %>% 
    step_dummy(all_nominal()) %>%
    step_normalize(all_numeric(), 
                   -all_outcomes()) %>% 
    prep(training = all_data)
walmart_recipe

all_data2 <- juice(walmart_recipe)

names(all_data2)
head(all_data2)
```

## 테스트, 트레인 셋 분리

전처리가 끝난 `all_data2`에서 `train`셋과 `test`셋을 분리함.

```{r}
# train, test
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]

train2 %>% dim()
```

## 모델 설정 및 학습

기본 패키지에 있는 `lm()`함수를 사용하여 선형 회귀를 사용하기 위하여, `set_engine()` 함수의 값을 "lm"으로 설정함. `fit()`를 사용해서 학습한다.

```{r}
lm_model <- 
    linear_reg() %>% 
    set_engine("lm")

lm_form_fit <- 
    lm_model %>% 
    fit(weekly_sales ~ ., data = train2)

lm_form_fit
```

## 예측 및 제출

`lm_form_fit`에 들어있는 정보를 사용하여 test셋에 대응하는 `weekly_sales`를 예측한다. 예측한 결과를 대회에서 제공하는 submission 파일에 넣어서 대회 홈페이지에 제출하면 끝!

```{r}
result <- predict(lm_form_fit, 
                  new_data = test2)

submission <- read_csv(file.path(file_path, "sampleSubmission.csv.zip"))
submission$Weekly_Sales <- result$.pred
write.csv(submission, row.names = FALSE,
          "baseline-lm-dummy-04022021.csv")
```

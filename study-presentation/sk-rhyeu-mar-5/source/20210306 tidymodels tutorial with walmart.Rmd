ㅈ---
title: "20210306 tidymodel tutorial with walmart"
author: "류성균"
date: '2021 3 6 '
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(lubridate)
library(magrittr)
library(plotly) # interactive ggplot
library(here) # dir 
library(parallel) # multi-processing
library(knitr)
```

```{r}
here()
```


# Walmart in `Tidymodels`

## Walmart mothership Data
```{r}
train <- read_csv(here("competition/walmart/train.csv.zip"))
test <- read_csv(here("competition/walmart/test.csv.zip"))
```


```{r}
train %<>% janitor::clean_names()
test %<>% janitor::clean_names()
```


```{r}
train %>% 
    select(date, weekly_sales) %>% 
    ggplot(aes(x = date, y = weekly_sales)) + 
    geom_line() -> p

ggplotly(p)
```

```{r}
set.seed(1234)
# walmart_folds <- vfold_cv(train, v = 5, strata = is_holiday)

walmart_validation <- validation_split(train,
                                       strata = is_holiday,
                                       prop = 0.7)
```


## Preprocess interface in `tidymodels`

 - recipe
     - step
        - step_corr()
        - step_center
        - step_scale
     - prep
 - workflow

### `recipe`
```{r}
walmart_recipe <- train %>% 
    recipe(weekly_sales ~ .) %>% 
        step_date(date, features = c("month")) %>% 
    step_rm(date)  %>% 
    step_mutate(
             # store = as.factor(store),
             # dept = as.factor(dept)
            # , date_year = as.factor(date_year)
            ) %>% 
    # step_dummy(all_nominal(), -all_outcomes()) %>%
    prep()

walmart_recipe %>% print()
```

```{r}
train_final <- juice(walmart_recipe)

# train_final %>% colnames()
train_final %>% 
    head() %>% 
    kable()
```

```{r}
walmart_recipe %>% 
    bake(test) %>% 
    # colnames()
    head() %>% 
    kable()
```


### random Forest `worflow`

```{r}
cores <- parallel::detectCores() -1
```


```{r}
rf_model <- 
    rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% 
    set_engine("ranger", seed = 1234, num.threads = cores) %>% 
    set_mode("regression")
```

```{r}
walmart_wflow <- workflow() %>% 
    add_model(rf_model) %>% 
    add_recipe(walmart_recipe)

walmart_wflow
```

#### hyperparameter tuning 
```{r}
set.seed(1234)

rf_result <- walmart_wflow %>% 
    tune_grid(walmart_validation,
              grid = 5,
              control = control_grid(save_pred = TRUE),
              metrics = metric_set(rmse))
```

```{r}
rf_result %>% show_best()
```

```{r}
rf_best <- 
    rf_result %>% 
    select_best(metric = "rmse")

rf_best
```

#### best fit with tuned hyperparameters
```{r}
### the last model
rf_best_model <- 
    rand_forest(mtry = rf_best$mtry, min_n = rf_best$min_n, trees = 1000) %>% 
    set_engine("ranger", seed = 1234, 
               num.threads = cores,
               importance = "impurity") %>% 
    set_mode("regression")


final_rf_wflow <- walmart_wflow %>% 
    update_model(rf_best_model)

set.seed(1234)
rf_best_fit <- final_rf_wflow %>% 
    fit(train)
```

```{r}
rf_best_fit
```

## submit prediction
```{r}
subfile <- read_csv(here("data/walmart/sampleSubmission.csv.zip"))


subfile$Weekly_Sales <- rf_best_fit %>% 
    predict(test) %>% 
    select(.pred) %>% unlist()


subfile


write.csv(subfile, row.names = FALSE,
          here("walmart/tuning-rf.csv"))

```

```{r}
last_week <- c(20660.01047 , 20238.71579)
today <- c(3672.12956, 3536.56464)

scores <- rbind(last_week, today) 
colnames(scores) <- c("private", "public" )
scores
```

- last week's score : 20660.01047 / 20238.71579
- today's score : 3672.12956 / 3536.56464



## Attachment 1 : CV with decision tree in `tidymodels`

```{r}
set.seed(1234)
walmart_split <- initial_split(train, prop = 0.7, strata = is_holiday)

walmart_split
```
```{r}
train_data <- walmart_split %>% training()
val_data <- walmart_split %>% testing()
```

```{r}
tune_spec <-
    decision_tree(
        cost_complexity = tune(),
        tree_depth = tune()
    ) %>% 
    set_engine("rpart") %>%     
    set_mode("regression")


tune_spec
```

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 3
)

tree_grid %>% head() %>% kable()

# tree_grid %>% count(cost_complexity)
# tree_grid %>% count(tree_depth)
```

```{r}
set.seed(1234)
walmart_folds <- vfold_cv(train, v= 5, strata = is_holiday)

# walmart_folds

tree_wf <- workflow() %>% 
    add_model(tune_spec) %>% 
    add_recipe(walmart_recipe)
```

```{r}
walmart_treefit <- 
    tree_wf %>% 
    tune_grid(
        resamples = walmart_folds,
        grid = tree_grid
    )


walmart_treefit
```

```{r}
walmart_treefit %>% 
    collect_metrics() %>% 
    head(12) %>% 
    kable()

```

```{r}
best_tree <- walmart_treefit %>% 
    select_best("rmse")

best_tree
```

```{r}
final_walmart_tree <-
    tree_wf %>% 
    finalize_workflow(best_tree)

final_walmart_tree
```

```{r}
walmart_treefit2 <- 
    final_walmart_tree %>% 
    fit(data = train_data)
```

```{r}
walmart_treefit2 %>% 
    predict(val_data) %>% 
    bind_cols(val_data) %>%  select(weekly_sales,.pred) %>% 
    metrics(truth = weekly_sales, estimate = .pred)
```


##  Attachment 2 :oridinary linear model fitting



```{r}
walmart_recipe2 <- train_data %>% 
    recipe(weekly_sales ~ .) %>% 
        step_date(date, features = c("month")) %>% 
    step_rm(date)  %>% 
    step_mutate(
             store = as.factor(store),
             dept = as.factor(dept)
            # , date_year = as.factor(date_year)
            ) %>% 
    step_dummy(all_nominal(), -all_outcomes()) %>% prep()

walmart_recipe2 %>% print()
```

```{r}
lm_model <- 
    linear_reg() %>% 
    set_engine("lm") %>% 
    set_mode("regression")
```


```{r}
walmart_wflow2 <- workflow() %>% 
    add_model(lm_model) %>% 
    add_recipe(walmart_recipe2)

walmart_wflow2
```

```{r}
walmart_lmfit <- walmart_wflow2 %>% 
    fit(train_data)
```

```{r}
juice(walmart_recipe2)
```


```{r}
walmart_lmfit %>% 
    predict(val_data) %>% 
    bind_cols(val_data) %>%  select(weekly_sales,.pred) %>% 
    metrics(truth = weekly_sales, estimate = .pred)
```

### ??

```{r}
walmart_lmfit %>% tidy()
```

```{r}
untidy_fit <- lm(weekly_sales ~ ., data = juice(walmart_recipe2))
```

```{r}
predict(untidy_fit, 
        newdata = 
            bake(walmart_recipe2, new_data = val_data)) %>% 
    bind_cols(val_data) %>%
    select(weekly_sales, '...1') %>%
    metrics(truth = weekly_sales,
            estimate = '...1')
```

```{r}
untidy_fit %>% summary()
```

- reference :
    - [A Gentle Introduction to tidymodels](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/)
    - [왜 당근(caret)은 안되고 새로운 신상 당근(Tidymodel)인가?](https://statkclee.github.io/ds-authoring/ds-why-tidymodels.html#/predictive-model)
    - [Tidymodels' GET STARTED](https://www.tidymodels.org/start/)



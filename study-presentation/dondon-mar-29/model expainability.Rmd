---
title: "Machine learning explainability"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```



## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels)
library(tidyverse)
library(lubridate)
library(skimr)
library(magrittr)
library(data.table)
library(gridExtra)

theme_set(theme_bw())
```



# Model-specific method {.tabset .tabset-fade}

## Random forest

![<https://towardsdatascience.com/random-forest-learning-essential-understanding-1ca856a963cb>](https://miro.medium.com/max/599/1*V1gaYbSzecaGE7s6WVIcsQ.png)

## Gini importance in random forest

**Single tree 일 때** $$
\begin{align*}
&VI_i = \sum_{n \in t, i_n = i} p(n) \boldsymbol{\Delta}_{gini}(n), \\
&i_n : \text{Sum over all nodes of the tree that use feature i} \\
&p(n) : \text{Probability of using that node for a sample data point} \\
&\boldsymbol{\Delta}_{gini}(n) : \text{Change in gini impurity at that node}
\end{align*}
$$

각 feature별 importance 값은 해당 feature가 선택된 노드의 gini impurity 값의 변화율?을 이용해서 계산된다.

밑에 예시를 통해 $X_1$, $X_2$ 변수의 gini importance가 어떻게 계산되는지 알아보자.

각 노드별로 gini impurity 값이 산출되었다고 했을 때, feature importance를 구하기 위해서는 $\boldsymbol{\Delta_{gini}}$의 값을 구해야한다.

$\boldsymbol{\Delta_{gini}}$를 어떻게 구하는지를 $X_1$ 변수를 기준으로 보면 기준노드의 gini impurity값과 split된 노드의 gini impurity값의 차이를 통해 계산된다. 정확히는 split된 노드에 해당하는 데이터의 비율을 gini impurity에 곱한 가중합과 기준 노드의 gini impurity 값의 차이를 통해 계산된다. $X_1$의 $\boldsymbol{\Delta_{gini}}$는 0.26으로 계산됨을 아래 이미지에서 확인할 수 있다.

이렇게 기준 변수에 해당하는 노드의 $\boldsymbol{\Delta_{gini}}$를 구했으면 마지막으로 $p(n)$ 즉, 해당 노드의 데이터의 비율을 곱해주고 모두 합해주면 개별 변수의 변수 중요도가 산출된다.

![<https://www.youtube.com/watch?v=qC3PRqHqnfE>](C:/Users/sangdon/AppData/Local/RStudio/tmp/paste-197ECBB6.png)

**Random forest일 때**

random forest일 때는 모델 특성상 각 부스트랩 샘플당 tree가 하나씩 나오게 되는데 각 tree에서 구한 $VI_i$ 값을 평균내주면 된다.

$$
\begin{align*}
VI_i=\frac{1}{|B|} \sum_{t \in B} VI_i(t)
\end{align*}
$$



## Purmutation importance in random forest

위에서 설명한 gini importance는 gini 값의 변화율 지표로 활용해서 feature importance를 산출하는 방법이다. purmutation importance도 위의 gini importance와 방식은 동일하지만 gini 값이 아닌 다른 지표를 활용한다는 것에서만 차이가 있다. 

$$
\begin{align*}
\text{within each tree } t \\
&VI^{(t)}(x_j) = \frac{\sum_{i=\bar B^{(t)}} I(y_i = \hat{y}_i^{(t)})}{|\bar B^{(t)}|} - \frac{\sum_{i=\bar B^{(t)}} I(y_i = \hat{y}_{i, \pi_j}^{(t)})}{|\bar B^{(t)}|}  \\
&\hat{y}_i^{(t)} = f^{(t)}(x_i) : \text{predicted class before permuting} \\
&\hat{y}_{i, \pi_j}^{(t)} = f^{(t)}(x_{i, \pi_j}) : \text{predicted class after permuting }X_j \\
&X_{i, \pi_j} = (x_{i,1}, \cdots, x_{i, j-1}, x_{\pi_j(i), j}, x_{i, j+1}, \cdots , x_{i, p}) \\ 
& \bar B^{(t)} = \text{out of bag sample} \\
\text{over all trees:} \\ 
&\text{1. row importance : } VI(x_j) = \frac{\sum_{t = 1}^{ntree}VI^{(t)}(x_j)}{ntree} \\ 
&\text{2. scale importance : } sVI(x_j) = \frac{VI(x_j)}{\frac{\hat{\sigma}}{\sqrt ntree}} \\ 
\end{align*}
$$
수식을 보면 개별 tree에 대해서 $t=1$일 때 $\sum_{i = B} I(y_i = \hat{y_i})$와 $\sum_{i = B} I(y_i = \hat{y_i, \pi_j})$ 의 차이를 통해 feature importance 값이 계산되고, 각 부스트랩 샘플에 해당하는 tree당 계산된 feature importance 값을 평균내주면 random forest에서의 feature importance 값이 계산된다. purmutation 개념은 밑에 설명이 나와있다. 



**R code**
```{r}
library(DALEXtra)

data(ames)
ames_train <- ames %>%
    transmute(Sale_Price = log10(Sale_Price),
              Gr_Liv_Area = as.numeric(Gr_Liv_Area), 
              Year_Built, Bldg_Type)

rf_model <- 
    rand_forest(trees = 1000) %>% 
    set_engine("ranger", importance = 'permutation') %>%  # rf 일 때는 importance 지정해줘야함 
    set_mode("regression")

rf_wflow <- 
    workflow() %>% 
    add_formula(
        Sale_Price ~ Gr_Liv_Area + Year_Built + Bldg_Type) %>% 
    add_model(rf_model) 

rf_fit <- rf_wflow %>% fit(data = ames_train)

rf_fit %>% 
  pull_workflow_fit()

rf_fit %>% 
  pull_workflow_fit() %>% 
  vip(geom = 'point')

```



**참고**

<https://www.zeileis.org/papers/Lifestat-2008.pdf>




# Model-agnostic method {.tabset .tabset-fade}

## Permutation importance

permutation importance는 **모델을 학습시킨 이후(post-hoc)** 특정 변수의 관측치를 shuffle했을 때의 예측력을 비교해서 feature importance를 계산하는 방법이다.

알고리즘 특성상 특정 모델에 국한된 방법이 아니라 어떤 모델이든 적용할 수 있는 방법이다. 

**Example**

사람의 10살 때의 정보를 이용해서 10년 후 20살 때의 키를 예측하려고 한다. 

직관적으로 변수 중 10살 때의 키에 관한 변수는 20살 때의 키를 예측하는데 중요한 변수이고, 10살 때 갖고 있는 양말의 수는 20살 때의 키를 예측하는데 중요한 변수가 아니다. 

이러한 직관에서 출발하면 다음과 같은 질문을 해볼 수 있다. 

validation set에서 특정 변수의 관측치를 shuffle하고, 나머지 변수를 고정시키면 예측 정확도에 어떤 영향을 미칠까?

![<https://www.kaggle.com/dansbecker/permutation-importance>](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%253A%252F%252Fblog.kakaocdn.net%252Fdn%252FcY8xmU%252FbtqHLexe9aU%252FJTfnc76PayQ0R7kZKJmyo0%252Fimg.png)

특정 한 변수의 관측치만 행방향으로 무작위로 섞기 때문에 당연히 모델의 예측력은 감소하게 될 것이다. 다만 변수별로 정도의 차이가 있을 수 있다. 즉, 위의 예시로 보면 10살 때의 키에 관한 변수를 shuffle 했을 때 모델의 예측력은 많이 떨어지지만, 10살 때 갖고 있는 양말의 수에 관한 변수를 shuffle 했을 때는 모델의 예측력에 큰 차이가 없을 수 있다. 이러한 직관이 purmutaion importance의 motivation이다.  

**Process**

1.  학습이 끝난 모델 세팅
2.  한 변수의 관측치를 shuffling한 데이터를 이용해서 동일하게 예측을 진행
3.  예측치와 실제값의 차이인 손실함수를 이용해서 shuffling 후에 얼마나 loss가 커졌는지 계산
4.  loss의 증감을 이용해서 feature importance를 계산
5.  모든 변수에 대해 반복

**장점**

-   계산 속도가 빠름

    -   특정 변수를 제거하고 재학습을 시키는 것이 아니라 특정 변수 하나를 permutation하는 것이므로 상대적으로 계산량 감소

-   사용 범위가 넓고, 직관적임

-   상대적으로 일관된 feature importance를 측정할 수 있음

**단점**

-   무작위로 shuffling 하다보면 비현실적인 값이 나올 수도 있음

-   weight의 구간을 이용한 해석 필요

**R code**

```{r}
svm_spec <- svm_poly(degree = 1, cost = 1/4) %>%
  set_engine("kernlab") %>%
  set_mode("regression")

svm_wflow <- 
    workflow() %>% 
    add_formula(
        Sale_Price ~ Gr_Liv_Area + Year_Built + Bldg_Type) %>% 
    add_model(svm_spec)

svm_fit <- svm_wflow %>% fit(data = ames_train)


# rf 아닐 때 permutation importance plot 그리는 법 
svm_fit %>%
  pull_workflow_fit() %>%
  vip(method = "permute", 
      target = "Sale_Price", metric = "rsquared",
      pred_wrapper = kernlab::predict, train = ames_train)
```

## Partial dependence plot

feature importance는 어떤 변수가 예측에 가장 큰 영향을 미쳤는지를 보여주고, partial dependence plot은 변수가 예측에 미치는 영향에 대해 보여줌.

pumutation importance와 마찬가지로 **모델을 학습한 후(post-hoc)** 계산함

**Example**

-   모든 주택에 관한 변수를 통제할 때, 위·경도는 주택가격에 어떤 영향을 미치는가?

-   두 그룹의 건강에 대한 예측 결과의 차이는 식단 때문인가? 아니면 다른 요인 때문인가?

**Process**

$$
\begin{align*}
\hat{f}_{x_s}(x_s) = E_{x_c}[\hat{f}(x_s, x_c)] &= \int \hat{f}(x_s, x_c)dP(x_c) \\
&\approx \frac{1}{n} \sum_{i=1}^n \hat{f}(x_s, x_c^{(i)})\quad  \text{using Monte Carlo}\\
&\hat{f} : \text{학습이 완료된 임의의 모델} \\ 
& x_s : \text{plot하고자 하는 변수} \\
& x_c : x_s\text{ 외 나머지 변수}
\end{align*}
$$

$\hat{f}$를 안다고 할 때, $x_{c}^{(i)}$ 는 데이터셋으로 부터 주어진 값이므로 $x_s$에 값을 넣어서 값을 얻을 수 있음.

**즉, 관심변수 외에 다른 변수들의 값이 고정되어 있을 때 관심 변수 값에 따라 모델의 예측값이 어떻게 변화하는지를 보는 것**

회귀분석과 관점이 비슷하고, 가정도 비슷함.

관심 변수와 관심변수 외의 변수들 간의 **독립**을 가정함

**장점**

-   해석이 직관적임

-   상대적으로 구현하기 쉬움

**단점**

-   2차원으로 표현되기 때문에 변수 2개에 대해서만 해석 가능

-   계산량이 많음

-   독립성 가정

**R code**

```{r}
library(DALEXtra)


data(ames)
ames_train <- ames %>%
    transmute(Sale_Price = log10(Sale_Price),
              Gr_Liv_Area = as.numeric(Gr_Liv_Area), 
              Year_Built, Bldg_Type)

rf_model <- 
    rand_forest(trees = 1000) %>% 
    set_engine("ranger") %>% 
    set_mode("regression")

rf_wflow <- 
    workflow() %>% 
    add_formula(
        Sale_Price ~ Gr_Liv_Area + Year_Built + Bldg_Type) %>% 
    add_model(rf_model) 

rf_fit <- rf_wflow %>% fit(data = ames_train)


explainer_rf <- explain_tidymodels(
    rf_fit, 
    data = dplyr::select(ames_train, -Sale_Price), 
    y = ames_train$Sale_Price,
    label = "random forest"
)

pdp_rf <- model_profile(explainer_rf, N = NULL, 
                        variables = "Gr_Liv_Area", groups = "Bldg_Type")

plot(pdp_rf)

```

## Shap value

**code**

# Preparations (준비작업) {.tabset .tabset-fade}

## Data load

```{r}
file_path <- "C:/Users/uos/Desktop/kaggle-study/competition/bike sharing/input/bike-sharing-demand"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv"))
test <- read_csv(file.path(file_path, "test.csv"))
```

# Data overview (데이터 기본정보)

## train data

```{r}
head(train)
skim(train)
```

## test data

```{r}
head(test)
skim(test)

test %>% 
  summarise(across(.fns = ~sum(is.na(.))/length(.)))

```

# data preprocessing

## combine train, test

```{r}
all_data <- bind_rows(train, test)

```

## Change variable type

```{r}
all_data$season <- factor(all_data$season, labels = c('winter', 'fall', 'summer', 'spring'))
all_data$weather <- as.factor(all_data$weather)
all_data$workingday <- as.factor(all_data$workingday)
all_data$holiday <- as.factor(all_data$holiday)
```

## create date variable

```{r}
all_data %>% mutate(year = year(datetime), 
                    month = month(datetime),
                    wday = wday(datetime),
                    day = day(datetime), 
                    hour = hour(datetime)) %>% 
    select(year, month, wday, day, holiday, workingday, everything()) -> all_data
```

## convert wday, month

```{r}
all_data$wday <- factor(all_data$wday, labels = c('Sun', 'Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat'))
all_data$month <- as.factor(all_data$month)
```

# Discretize

humidity의 경우 0 값이 22개 존재함. humidiy 값이 0인 경우를 결측치 대체함. windspeed가 0인 경우도 마찬가지로 결측치로 보고 대체함 weather의 경우 4 level의 빈도가 매우 작기 때문에 3 level과 통합

```{r}
all_data %>% 
    recipe(count~.) %>% 
    step_other(weather, threshold = 0.1, other = 3) %>% 
    step_discretize(windspeed, min_unique = 5, num_breaks = 5) %>%
    #step_discretize_xgb(windspeed)
    prep(training = all_data) %>% 
    bake(new_data = all_data) -> all_data
```

# Recipe + preperation

```{r}
bike_res <- all_data %>% 
  recipe(count~.) %>% 
  step_rm(datetime, registered, casual) %>%
  step_mutate(year = as.factor(year)) %>% 
  step_log(count, offset = 1) %>%
  step_dummy(all_nominal()) %>%
  step_nzv(all_numeric()) %>% 
  prep(training = all_data)
    
```

# Juice

```{r}
all_data2 <- juice(bike_res)
```

# Split train, test

```{r}
train_index <- seq_len(nrow(train))
train2 <- all_data2[train_index,]
test2 <- all_data2[-train_index,]
```

# XGboost setting

## XGBOOST hyperparameter setting

```{r}
xgb_spec <- boost_tree(
    trees = 1000, # 앙상블에 포함되는 tree의 수 
    tree_depth = tune(), # 얼마만큼 노드를 split할건지 
    min_n = tune(), # 노드를 분할하는데 필요한 최소 데이터의 수
    loss_reduction = tune(), # 노드 분할에 필요한 loss의 감소량 
    sample_size = tune(), # The amount of data exposed to the fitting routine
    mtry = tune(), # The number of predictors that will be randomly sampled at each split when creating the tree models. 
    learn_rate = tune() 
) %>% 
    set_engine('xgboost', objective = "reg:squarederror") %>% 
    set_mode('regression')

params <- parameters(xgb_spec) %>% 
    finalize(train2)
```

# XGboost workflow

## workflow model setting

```{r}
xgb_wf <- workflow() %>% 
    add_formula(count~.) %>% 
    add_model(xgb_spec)
```

## cross validation

```{r}
set.seed(2021)
vb_folds <- vfold_cv(train2, v = 5, strata = count)
vb_folds
```

## bayes tuning

```{r}
library(tictoc)
tic()
doParallel::registerDoParallel()
xgb_res <- tune_bayes(
    object = xgb_wf, # recipe, formula를 지정해준 workflow 
    resamples = vb_folds, 
    param_info = params, 
    iter = 30, 
    metrics = metric_set(rmse), 
    initial = 10, 
    control = control_bayes(
        verbose = TRUE, 
        no_improve = 10, 
        seed = 123) 
)
toc()  # 1268
```

## Final model update

```{r}
best_param <- select_best(xgb_res, 'rmse')
final_xgb <- finalize_workflow(xgb_wf, best_param)
```

## final model setting

```{r}
final_model <- finalize_model(xgb_spec, best_param) 
```

## final model workflow에 업데이트

```{r}
final_workflow <- xgb_wf %>% update_model(final_model)
```

## final model 학습

```{r}
xgb_fit <- fit(final_workflow, data = train2)
```

# Result

## Prediction

```{r}
pred_xgb <- 
    predict(xgb_fit, test2) %>% 
    mutate(modelo = "XGBoost")

pred_xgb$.pred <- exp(pred_xgb$.pred)-1
```

## feature importance plot

```{r}
library(vip) # feature importance plot 그리기 
final_xgb %>% 
    fit(data = train2) %>%  # iter, training_rmse 
    extract_fit_parsnip() %>% # Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
    vip(geom = 'point')
```

## partial dependence profile

```{r}
library(DALEXtra)
explainer_xgb <- explain_tidymodels(
    xgb_fit, 
    data = dplyr::select(train2, -count), 
    y = train2$count,
    label = "XGBOOST"
)
pdp_xgb <- model_profile(explainer_xgb, N = NULL, 
                        variables = "temp")
plot(pdp_xgb)

pdp_xgb2 <- model_profile(explainer_xgb, N = NULL, 
                        variables = "humidity")

plot(pdp_xgb2)
```

-   온도가 올라갈수록 자전거를 타는 횟수가 증가함.
-   습도가 0\~25 사이에서는 자전거를 타는 횟수가 증가하지만, 75이상부터는 자전거를 타는 횟수가 급격하게? 감소함(축 값이 작음)

## SHAP value

```{r}
xgb_mod <- final_xgb %>% 
  fit(data = train2) %>%   
  extract_fit_parsnip() 

X <- train2 %>% 
  select(-count) %>% 
  as.matrix()
shap <- explain(xgb_mod$fit, X = X, pred_wrapper = predict)

autoplot(shap)
autoplot(shap, type = 'dependence' ,feature = 'hour', X = train2)
autoplot(shap, type = 'contribution' ,row_num = 1) # explain first row of X 

```

참고자료

<https://www.kaggle.com/dansbecker/use-cases-for-model-insights>

<https://www.kaggle.com/dansbecker/permutation-importance>

<https://www.kaggle.com/dansbecker/partial-plots?scriptVersionId=64768853&cellId=1>

<https://christophm.github.io/interpretable-ml-book/pdp.html>

<https://juliasilge.com/blog/mario-kart/>

<https://www.hfshr.xyz/posts/2020-06-07-variable-importance-with-fastshap/#ref-R-vip>

<https://stackoverflow.com/questions/67634344/r-partial-dependence-plots-from-workflow>

<https://cran.r-project.org/web/packages/fastshap/fastshap.pdf>

<https://www.youtube.com/watch?v=lIT5-piVtRw>

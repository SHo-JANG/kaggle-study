---
title: "tidymodels modeltime"
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 5
    fig_height: 4
    theme: cosmo
    highlight: tango
    code_folding: show
---

# Introduction

**Modeltime** 패키지는 tidymodels와 연동 가능한 시계열 모델링 관련 패키지입니다. tidymodels에도 물론 Auto arima, MA 모형 같은 간단한 시계열 모델이 있지만 다른 머신러닝 모델에 비해서 쓸 수 있는 모델이 제한적입니다. **Modeltime** 패키지는 이러한 tidymodels의 단점을 보완하기 위해서 시계열 모델링에 특화된 패키지로 이해하시면 될 것 같습니다.

**Modeltime** 패키지는 하나의 단일 패키지가 아니라 다양한 머신러닝, 딥러닝 패키지와 연동해서 하나의 시계열 생태계를 구축하고 있습니다.

대표적인 패키지는 다음과 같습니다.

-   Modeltime : 시계열 머신러닝 관련 패키지

-   Modeltime.H2O : H2O의 autoML과 연동이 가능한 패키지

-   Modeltime.GluonTS : 시계열 관련 딥러닝 패키지(**N-beats**, **deep AR model** 제공)

-   Modeltime.Ensemble : Modeltime 관련 앙상블 패키지

-   Modeltime.Resample : Backtesting 관련 패키지

-   Timetk : feature engineering, Data wrangling, time series visualization

**Modeltime.GluonTS의 경우 python 패키지를 불러오는 것이기 때문에 몇가지 설치 이슈가 있습니다. 자세한 사항은 설치 관련 공식 링크를 참고하시면 될 것 같습니다.**

설치 관련 링크\
<https://cran.r-project.org/web/packages/modeltime.gluonts/vignettes/getting-started.html>

<https://business-science.github.io/modeltime.gluonts/articles/managing-envs.html>

# Modeltime workflow

Modeltime 패키지는 시계열 모델링에 맞는 고유한 워크플로우가 존재하며, tidymodels와 마찬가지로 이 워크플로우 그대로 진행을 해야만 에러 없이 동작합니다. 사실 실제 시계열 모델링할 때와 동일한 매커니즘이어서 어색함 없이 따라할 수 있습니다.

workflow의 순서는 다음과 같습니다.

1.  Create modeltime table

    -   다양한 모델을 training data에 fitting하고 modeltime table에 저장하는 단계

    -   모델이 재대로 fitting 되었는지 확인할 수 있고, 워크플로우에 맞는 table 구성

2.  Calibrate

    -   modeltime table에 저장된 모델을 test 데이터에 fitting하는 단계

    -   test data에 fitting함으로써 모델의 성능 파악 가능

3.  Refit

    -   training data, test data를 합친 original data에 refit하는 단계

    -   refit한 모델을 이용해서 forecast를 진행

# Model

Modeltime 패키지는 다양한 시계열 모델을 지원하는데 대표적인 모델은 다음과 같습니다.

-   auto_arima_boost: a automatic ARIMA boosted model specification
-   arima_reg : arima regression model
-   exp_smoothing : automated exponential smoothing
-   prophet_boost: a prophet model specification
-   prophet_boost_log: a prophet model specification with logarithmic growth
-   mars: a Multivariate Adaptive Regression Splines model specification
-   nnetar: a Neural network time series model specification

Modeltime 패키지의 한 가지 단점은 패키지를 만든 저자가 business-science라는 course를 운영 중인 것 같은데 Modeltime 관련 세부 자료(hyperparameter tuning 관련)는 유료 course에서 공개를 하는 것 같습니다...

# Preparations (준비작업) 

## Libraries

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidyverse)
library(tidymodels)
library(lubridate)
library(data.table)
library(skimr)
library(tibble)
library(tibbletime)
library(timetk)
library(forecast)
library(modeltime)
library(gt)
library(timetk)
library(lubridate)
library(janitor)
library(tidyquant)
library(modeltime.resample)
library(modeltime.ensemble)

# Visualization
library(ggthemes)
library(ggsci)
library(viridis)
library(ggExtra)


theme_set(theme_bw())
```

## Data load 

```{r}
file_path <- "./data/"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
rdata2 <- fread(file.path(file_path, "rdata2.csv"))
```

# Data overview (데이터 기본정보) 

## train data

태양광 발전소의 위치는 크게 울산과 당진으로 나뉩니다. 튜토리얼을 위해서 울산 지역 데이터를 이용해서 분석을 진행해보겠습니다.

울산 지역 데이터에 대한 간략한 개요는 다음과 같습니다.

```{r}

glimpse(rdata2)
skim(rdata2)

```

# Univariate timeseries analysis

간략하게 Modeltime 패키지의 workflow를 설명하기 위해서 단변량 시계열 모형을 구축해보겠습니다.

# 데이터 전처리 

## Change data type

총 데이터에서 기상 관련 변수를 제외하고 lubridate 패키지를 이용해서 날짜변수를 처리했습니다.

```{r}
rdata2 %>%
    dplyr::select(time, ulsan) %>% 
    mutate(time = ymd_hms(time)) %>% 
    rename(date = time, value = ulsan) %>%  
    dplyr::filter(between(date, ymd('2015-02-01'), ymd('2021-02-01'))) -> ulsan

```

## Generate future frame

분석의 목적이 2021년 2월 한달을 예측하는 것이기 때문에 추후 forecast를 할 때 적용할 데이터 프레임을 생성해주어야 합니다.

```{r}
future_tbl <- 
    future_frame(.data = ulsan, .date_var = date, .length_out = '1 month') %>% 
    mutate(value = NA, 
           value = as.integer(NA))

```

## Standardization

targer 변수에 대해서 간단하게 standardization을 해주었습니다. 예측 이후에 재변환을 해줘야하기 때문에 관련 파라미터를 따로 작성해두었습니다.

```{r}
ulsan %>% 
    mutate(value = standardize_vec(value)) -> ulsan

#Standardization Parameters
#mean: 66.3113618827161
#standard deviation: 104.187665325827
```

## Data split

```{r}
splits <- time_series_split(ulsan, assess = "1 month", cumulative = TRUE)
splits %>% 
    tk_time_series_cv_plan() %>% 
    plot_time_series_cv_plan(date, value,
                           .interact = TRUE, 
                           .title = "Partition Train / Test")
```

# Feature engineering

feature engineering 단계는 기존 tidymodels의 workflow에서 활용했던 recipe를 동일하게 이용할 수 있습니다. modeltime과 timetk 패키지에는 recipe에서 활용할 수 있는 여러가지 시계열 관련 전처리 함수를 제공해주고 있습니다.

```{r}
ulsan_recipe <- 
    recipe(value~., data = training(splits)) %>% 
    step_timeseries_signature(date) %>% 
    step_rm(matches("(iso)|(xts)|(quarter)|(year)|(month)|(qday)|(diff)")) %>% 
    #step_lag(value, lag = 1:6) %>% 
    step_normalize(matches("(index.num)|(yday)")) %>% 
    step_dummy(all_nominal(), one_hot = TRUE) %>% 
    step_interact(~ matches("am.pm") * matches("wday.lbl")) %>% 
    step_fourier(date, period = c(24, 48, 76), K=2)
    
ulsan_recipe %>% prep() %>% juice() %>% head()

```

# Time series workflow 

## Model fitting

Model fitting은 tidymodels 패키지의 방식과 동일합니다. 현재는 default 세팅으로 모델을 fitting했지만 튜닝 파라미터가 있을 경우 tidymodels에서 했던 workflow를 이용해서 튜닝을 진행할 수 있습니다. 다만 validation set 세팅에 있어서 시계열 데이터에 맞는 validation set을 세팅해야하고, 모델 별로 고유한 튜닝 파라미터와 각 튜닝 파라미터별 범위를 정확히 지정해주어야 합니다.

```{r}
model_fit_prophet <- prophet_reg(seasonality_daily = TRUE) %>%
    set_engine(engine = "prophet") 

wflw_fit_prophet <- workflow() %>% 
    add_recipe(ulsan_recipe) %>%
    add_model(model_fit_prophet) %>%
    fit(training(splits)) 


model_fit_prophet_xgboost <- prophet_boost(seasonality_daily = TRUE) %>%
    set_engine(engine = "prophet_xgboost")

wflw_fit_prophet_boost <- workflow() %>% 
    add_recipe(ulsan_recipe) %>%
    add_model(model_fit_prophet_xgboost) %>% 
    fit(training(splits))


model_fit_nnetar <- nnetar_reg() %>% 
    set_engine('nnetar')

wflw_fit_nnetar <- workflow() %>% 
    add_recipe(ulsan_recipe) %>% 
    add_model(model_fit_nnetar) %>% 
    fit(training(splits))

```

## Model table

modeltime_table에 fitting한 모델을 추가합니다. modeltime_table은 이전에 서술했다시피 각 모델이 재대로 적합되었는지 확인하고, 이후 예측 워크플로우를 위해서 modeltime_table 구조를 이용하므로 model table을 에러 없이 세팅하는 것이 중요합니다.

```{r}
model_tbl <- modeltime_table(
  wflw_fit_prophet, 
  wflw_fit_prophet_boost, 
  wflw_fit_nnetar
)
```

## Calibration

이전에 만든 modeltime_table을 test 데이터에 적합시켜서 보정을 하는 단계입니다. 각 모델 별 평가지표를 통해서 성능을 확인할 수 있습니다.

```{r}
calibration_tbl <- model_tbl %>% 
  modeltime_calibrate(new_data = testing(splits))
```

```{r}
calibration_tbl %>% 
    modeltime_accuracy(testing(splits)) %>%
    table_modeltime_accuracy(.interactive = FALSE)
```

## Refit

train/test를 합한 original 데이터를 이용해서 refitting을 진행하는 단계입니다.

```{r}
refit_tbl <- calibration_tbl %>% 
    modeltime_refit(data = ulsan) 
```

## Forecast

refitting된 모델을 이용해서 지정한 time interval에 대해 forecast를 수행하는 단계입니다. 데이터 전처리 단계에서 target 변수에 대해서 standardization을 했기 때문에 forecast 단계에서는 역변환을 해주어야 합니다.

```{r}
refit_tbl %>% 
    modeltime_forecast(
        new_data = future_tbl, 
        actual_data = ulsan 
    ) %>% 
    mutate(across(.value, .fns = ~ standardize_inv_vec(
        x = .,
        mean = 66.3113618827161,
        sd = 104.187665325827
    ))) -> result_tbl

# write.csv(result_tbl, 'result_tbl.csv')

#mean: 66.3113618827161
#standard deviation: 104.187665325827
    
```

# Ensemble workflow 
다음은 Modeltime.ensemble 패키지에 대해 설명드리겠습니다. 보통 여러가지 모델을 fitting하고 모델의 성능을 조금이라도 올리기 위해 앙상블을 해서 최종 모델을 생성을 합니다. Modeltime.ensemble은 이를 간단한 함수로 실현시켜주는 패키지라고 생각하시면 됩니다.

stacking 관련 함수는 따로 제공됩니다(관련 링크 : <https://cran.r-project.org/web/packages/modeltime.ensemble/modeltime.ensemble.pdf> )

## Make an ensemble average

가장 간단한 앙상블 방법으로 평균을 이용하는 방법이 있습니다. Modeltime.ensemble 패키지에서는 Modeltime 패키지를 이용해서 fitting한 모델들을 간단한 함수를 통해서 결과를 산출해줍니다.

평균으로 앙상블을 하려면 ensemble_average() 함수에서 type=**'mean'** 으로 설정하면 됩니다. 중앙값으로 앙상블을 하려면 type=**'median'** 으로 설정하면 됩니다.

```{r}
# model_tbl <- modeltime_table(
#   wflw_fit_prophet, 
#   wflw_fit_prophet_boost, 
#   wflw_fit_nnetar
# )

ensemble_average_fit <- model_tbl %>% 
    ensemble_average(type = 'mean') %>% 
    modeltime_table() %>% 
    modeltime_calibrate(testing(splits))

ensemble_average_fit %>% 
    modeltime_accuracy(testing(splits)) %>%
    table_modeltime_accuracy(.interactive = FALSE) 

```

## Make an weighted ensemble

여러가지 모델을 fitting 했을 때 모델별로 성능에 차이가 있습니다. 이를 고려하지 않고 평균을 이용해서 앙상블을 할 경우 최종 모델의 성능이 떨어질 수 있습니다. 이를 보완하기 위해서 성능이 좋은 모델에는 더 큰 가중치를 부여하고 성능이 안좋은 모델에는 작은 가중치를 부여하는 weighted ensemble 방법이 있습니다. 제가 적합한 모형의 경우 prophet boost의 성능이 더 좋기 때문에 prophet boost의 가중치를 가장 크게 부여했습니다.

weighted ensemble 관련 함수 설명은 다음과 같습니다.

**ensemble_weighted(object, loadings, scale_loadings = TRUE)**

-   object : A Modeltime Table
-   loadings : A vector of weights corresponding to the loadings
-   scale_loadings : If TRUE, divides by the sum of the loadings to proportionally weight the submodels.

```{r}
ensemble_weighted_fit <- model_tbl %>% 
    ensemble_weighted(loadings = c(1 ,8, 1), scale_loadings = TRUE) %>% 
    modeltime_table() %>% 
    modeltime_calibrate(testing(splits))

ensemble_weighted_fit %>% 
    modeltime_accuracy(testing(splits)) %>%
    table_modeltime_accuracy(.interactive = FALSE) 

ensemble_weighted_fit  %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = ulsan
    ) %>%
    plot_modeltime_forecast(.interactive =FALSE)

```

## Refit on Full Data & Forecast Future

Refit, forecast 과정도 Modeltime workflow와 동일한 방식으로 진행하면 됩니다.

```{r}

refit_ensemble_weighted_fit <- ensemble_weighted_fit %>% 
    modeltime_refit(ulsan)


refit_ensemble_weighted_fit %>% 
    modeltime_forecast(
        new_data = future_tbl,
        actual_data = ulsan
    ) %>% mutate(across(.value, .fns = ~ standardize_inv_vec(
        x = .,
        mean = 66.3113618827161,
        sd = 104.187665325827
    ))) -> ensemble_result 

ensemble_result %>% tail()

```

---
title: "credit card_dacon"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r cars}
library(tidyverse)
library(skimr)
library(tidymodels)
library(magrittr)

train <- read.csv("dataset/train.csv", na.strings = c("","NA"))
train %>% janitor::clean_names() ->train
test <- read.csv("dataset/test.csv",na.strings = c("","NA"))
test %>% janitor::clean_names() -> test

names(train)
dim(train)
names(test)
dim(test)

# alldata <- bind_rows(train, test)
# dim(alldata)
# 
# skim(alldata)
```

* days_birth : -값은 무슨 의미인지. 연도도 아니고 무슨 값인지 모르겠음. 
* days_employed : -값은 무슨 의미인지. 365일로 나눠서 연으로 살펴봐도 편할 듯
* 카테고리형 features : child_num, flag_mobil, family_size, gender, car
* house_type : 입력은 단답식인데, min/max가 있다니?
* occyp_type : 전문직, 기술직, 사무직 등으로 나눌 수 있을 듯


1) gender: 성별의 credit 분포
```{r cars}
train %>% filter(!is.na(credit)) %>%
    ggplot(aes(x=credit), na.rm=TRUE)+
    geom_bar()+
    theme_bw()


train %>% filter(!is.na(credit)) %>%
    ggplot(aes(x=credit), na.rm=TRUE)+
    geom_bar()+
    facet_grid(.~gender)
    theme_bw()

##upsampling
```

2) days_birth: 나이별 신용 분포
```{r cars}
train %>% select(days_birth) %>% summary()

train<-train %>%
    mutate(days_birth_year = abs(ceiling(days_birth/360))) 

train %>% select(days_birth, days_birth_year, credit) %>% head()



train %>% filter(!is.na(credit)) %>%
    ggplot(aes(x=days_birth_year))+
    geom_histogram()+
    facet_grid(.~credit)


train %>% head()

```


3) income_type 별 신용도




3) occyp_type: 직업군과 수입의 관계/직업군과 신용의 관계 비교

```{r}
skim(train$occyp_type) #complete rating 0.69/ missing rating 0.31



train %>% filter(!is.na(occyp_type)) %>% 
    group_by(occyp_type) %>% 
    summarise(income_total=mean(income_total)) %>% 
    ggplot(aes(x=occyp_type, y=income_total))+
    geom_bar(stat = 'identity')+
    theme_bw()+
    theme(axis.text.x=element_text(angle=90, hjust=1))


train %>% filter(!is.na(occyp_type)&!is.na(credit)) %>% 
    select(c(occyp_type, credit)) %>% # 직업타입별, 신용도 살펴보기
    ggplot(aes(x=occyp_type,  fill=as.factor(credit)))+
    geom_bar(position=position_dodge())+
    theme_bw()+
    scale_fill_brewer(palette="Pastel1")+
    theme(axis.text.x = element_text(angle=90, hjust=1))


#직업간의 sample 수 편차가 심한 듯     
    
```





### modeling - recipe
```{r}


library(themis)
library(recipes)
library(caret)
library(rpart)
library(ROCR)
library(xgboost)
```

```{r}
table(train$credit)
prop.table(table(train$credit)) # class imbalance in percentage


train$credit <- as.factor(train$credit)
levels(train$credit)


table(train$credit)

set.seed(123)
up_sample <- upSample(x=train[, -ncol(train)],
                      y=train$credit)


table(up_sample$credit)





```





```{r}
set.seed(1234)

up_sample$credit-> labels
y<- recode(labels, "0"=0, "1"=1, "2"=2)

set.seed(123)

xgb <- xgboost(data=data.matrix(up_sample[,]),
               label=y,
               eta=0.1,
               gamma=0.1,
               max_depth=10,
               nrounds=300)

xgb_pred <- predict(xgb, data.matrix(test[,]))

names(train)

names(test)

```


```{r}
cores <- parallel::detectCores()-1
cores


tune_spec <- rand_forest(mtry = tune(),
                         min_n = tune(),
                         trees = 300) %>% 
    set_engine("ranger",
               num.threads = cores) %>% 
    set_mode("classification")


param_grid <- tibble(mtry = 3, min_n = 5)

```
```{r}
workflow <-workflow() %>%
    add_model(tune_spec) %>%
    add_formula(credit~.)


workflow
```


```{r}
train_index <- seq_len(nrow(train))
train2 <- alldata_juice[train_index,]
test2 <- alldata_juice[-train_index,]

skim(alldata_juice)

```



```{r}
library(tictoc)

set.seed(123)
validation_split <- validation_split(train2, 
                                     prop = 0.7,
                                     strata = credit)


tic()
tune_result <- workflow %>%
    tune_grid(validation_split,
              grid=param_grid,
              metrics=metric_set(mn_log_loss))
toc()

```



```{r}
tune_result %>%
    collect_metrics()


```


```{r}
tune_result %>% show_best()


tune_best <- tune_result %>% select_best(metric = "mn_log_loss")
tune_best$mtry
tune_best$min_n


```


```{r}
rf_model <- rand_forest(mtry = tune_best$mtry,
                        min_n=tune_best$min_n,
                        trees=300) %>%
    set_engine("ranger", seed=123,
               num.threads=cores) %>%
    set_mode("classification")






```


```{r}
tictoc::tic()
rf_fit <- rf_model %>%
    fit(credit~., data=train2)
tictoc::toc()

options(max.print=10)
rf_fit



# 7.22 sec elapsed
# parsnip model object
# 
# Fit time:  6.3s 
# Ranger result
# 
# Call:
#  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~tune_best$mtry,      x), num.trees = ~300, min.node.size = min_rows(~tune_best$min_n,      x), seed = ~123, num.threads = ~cores, verbose = FALSE, probability = TRUE) 
# 
# Type:                             Probability estimation 
# Number of trees:                  300 
# Sample size:                      26457 
# Number of independent variables:  18 
# Mtry:                             3 
# Target node size:                 5 
# Variable importance mode:         none 
# Splitrule:                        gini 
# OOB prediction error (Brier s.):  0.2301916 




```

```{r}

result <- predict(rf_fit, test2, type="prob")
result %>% head()



```




```{r}
submission <- read_csv("open/sample_submission.csv")
sub_col <- names(submission)


submission <- bind_cols(submission$index, result)

names(submission) <- sub_col
write.csv(submission, row.names=FALSE,
          "baseline_credit_Issac.csv")


```










